chatGPT aug:
Those who should be re-evaluated: 30/7088 in mutual, 48/7088 in mutual_plus

As dataset is adapted from 高考英语听力 and many choices are similar to "Pardon?", 
chatGPT likely consider the "Pardon?" slightly more reasonable than other wrong ones.

No true answer told to chatGPT for ranking/sorting

It may output "=", or only one ">" if it consider the wrong ones are equally bad answers.

if a choice is also a question, chatGPT may also consider it reasonable no matter whether there are factual errors in the question.

In mutual_plus, many right answers in mutual are replaced by sentences like "Pardon?" while other choices are wrong logically, which can test LM's logic ability in a tougher way.


mutual
原版 'r1': 0.9234234234234234, 'r2': 0.9774774774774775, 'mrr': 0.9577702702702702
t=0.001 
0.01  ×
0.05 ×
0.1 'r1': 0.9211711711711712, 'r2': 0.9752252252252253, 'mrr': 0.9558933933933934}
0.5 'r1': 0.9076576576576577, 'r2': 0.9662162162162162, 'mrr': 0.9476351351351349}
0.75 x
1 'r1': 0.9211711711711712, 'r2': 0.9752252252252253, 'mrr': 0.9564564564564563}

mutual +
原版 'r1': 0.8423423423423423, 'r2': 0.9594594594594594, 'mrr': 0.9140390390390388}
t=0.001 'r1': 0.8490990990990991, 'r2': 0.9594594594594594, 'mrr': 0.9172297297297296 || 'r1': 0.8423423423423423, 'r2': 0.9572072072072072, 'mrr': 0.9134759759759759
0.01 ×
0.05 ×
0.1 'r1': 0.8468468468468469, 'r2': 0.954954954954955, 'mrr': 0.9153528528528526}
0.5 ×
0.75 'r1': 0.8400900900900901, 'r2': 0.9572072072072072, 'mrr': 0.9127252252252248}
1 'r1': 0.8423423423423423, 'r2': 0.9527027027027027, 'mrr': 0.9127252252252251}